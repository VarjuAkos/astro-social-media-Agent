from langchain_groq import ChatGroq
from langchain.schema import SystemMessage, HumanMessage
from config.settings import settings
import logging
import json
from typing import Dict, Any

logger = logging.getLogger(__name__)

class AIService:
    def __init__(self):
        if not settings.groq_api_key:
            raise ValueError("GROQ_API_KEY environment variable is required")
        
        self.llm = ChatGroq(
            api_key=settings.groq_api_key,
            model=settings.model_name,
            temperature=settings.temperature,
            max_tokens=settings.max_tokens
        )
        logger.info(f"Using Groq API with model: {settings.model_name}")
        print(f"ü§ñ AI Service initialized with Groq model: {settings.model_name}")
    
    async def analyze_context(self, campaign_message: str, target_audience: str, tone: str) -> Dict[str, Any]:
        """First step: Analyze campaign context and generate initial ideas."""
        
        print("\nüîç AI SERVICE: CONTEXT ANALYSIS")
        print("-" * 50)
        
        system_prompt = """
        Te egy kreat√≠v magyar marketing szak√©rt≈ë vagy. A feladatod hogy elemezd a kamp√°ny√ºzenetet √©s c√©lk√∂z√∂ns√©get, 
        majd √∂tleteket gener√°lj a k√ºl√∂nb√∂z≈ë k√∂z√∂ss√©gi m√©dia platformokra.
        
        Fontoss√°gi sorrend:
        1. Magyar nyelv haszn√°lata (angol szavak csak indokolt esetben)
        2. Platform-specifikus st√≠lus √©s korl√°tok figyelembev√©tele
        3. C√©lk√∂z√∂ns√©g saj√°toss√°gainak meg√©rt√©se
        4. Kreat√≠v √©s engaging tartalom l√©trehoz√°sa
        """
        
        human_prompt = f"""
        Kamp√°ny√ºzenet: {campaign_message}
        C√©lk√∂z√∂ns√©g: {target_audience}
        Hangnem: {tone}
        
        Elemezd a kamp√°ny kontextus√°t √©s adj vissza:
        1. Kulcs√ºzenetek azonos√≠t√°sa
        2. C√©lk√∂z√∂ns√©g motiv√°ci√≥i √©s √©rdekl≈ëd√©si ter√ºletei
        3. Platform-specifikus megk√∂zel√≠t√©si strat√©gi√°k
        4. Kreat√≠v ir√°nyok √©s √∂tletek
        
        V√°laszold JSON form√°tumban:
        {{
            "key_messages": ["√ºzenet1", "√ºzenet2"],
            "audience_insights": "c√©lk√∂z√∂ns√©g elemz√©se",
            "platform_strategies": {{
                "facebook": "strat√©gia",
                "instagram": "strat√©gia", 
                "linkedin": "strat√©gia",
                "x": "strat√©gia"
            }},
            "creative_directions": ["ir√°ny1", "ir√°ny2", "ir√°ny3"]
        }}
        """
        
        print("üì§ SENDING TO AI:")
        print(f"   System Prompt: {system_prompt[:100]}...")
        print(f"   Human Prompt: {human_prompt[:200]}...")
        print("   Full prompts logged below:")
        print("\nüîß FULL SYSTEM PROMPT:")
        print(system_prompt)
        print("\nüìù FULL HUMAN PROMPT:")
        print(human_prompt)
        
        try:
            messages = [SystemMessage(content=system_prompt), HumanMessage(content=human_prompt)]
            print("\n‚è≥ Sending request to Groq API...")
            response = await self.llm.ainvoke(messages)
            
            print(f"\nüì• RAW AI RESPONSE:")
            print(f"   Length: {len(response.content)} characters")
            print(f"   Content: {response.content}")
            
            # Try to parse JSON response
            parsed_response = json.loads(response.content)
            print(f"\n‚úÖ PARSED JSON RESPONSE:")
            print(json.dumps(parsed_response, indent=2, ensure_ascii=False))
            return parsed_response
            
        except json.JSONDecodeError as e:
            print(f"\n‚ùå JSON PARSE ERROR: {e}")
            print(f"   Raw content: {response.content}")
            logger.error(f"Failed to parse context analysis response: {response.content}")
            # Return a default structure that matches expected format
            fallback = {
                "key_messages": ["Kamp√°ny √ºzenet elemz√©se"],
                "audience_insights": f"C√©lk√∂z√∂ns√©g: {target_audience}",
                "platform_strategies": {
                    "facebook": "R√©szletes tartalom megoszt√°sa",
                    "instagram": "Vizu√°lis tartalom hangs√∫lyoz√°sa", 
                    "linkedin": "Professzion√°lis megk√∂zel√≠t√©s",
                    "x": "R√∂vid, t√∂m√∂r √ºzenetek"
                },
                "creative_directions": ["Engaging tartalom", "Platform-specifikus optimaliz√°ci√≥", "C√©lk√∂z√∂ns√©g-f√≥kusz"]
            }
            print(f"üîÑ Using fallback response: {json.dumps(fallback, indent=2, ensure_ascii=False)}")
            return fallback
        except Exception as e:
            print(f"\n‚ùå AI SERVICE ERROR: {e}")
            logger.error(f"Context analysis failed: {e}")
            # Return a default structure instead of error dict
            fallback = {
                "key_messages": ["Kamp√°ny √ºzenet"],
                "audience_insights": f"C√©lk√∂z√∂ns√©g: {target_audience}",
                "platform_strategies": {
                    "facebook": "√Åltal√°nos strat√©gia",
                    "instagram": "Vizu√°lis tartalom", 
                    "linkedin": "Professzion√°lis tartalom",
                    "x": "R√∂vid tartalom"
                },
                "creative_directions": ["Kreat√≠v megk√∂zel√≠t√©s"]
            }
            print(f"üîÑ Using fallback response due to error: {json.dumps(fallback, indent=2, ensure_ascii=False)}")
            return fallback
    
    async def generate_platform_posts(self, context: Dict, campaign_message: str, 
                                    target_audience: str, tone: str, use_emojis: bool) -> Dict[str, Dict]:
        """Second step: Generate platform-specific posts based on context analysis."""
        
        print("\nüìù AI SERVICE: PLATFORM POSTS GENERATION")
        print("-" * 50)
        
        emoji_instruction = "Haszn√°lj relev√°ns emojikat" if use_emojis else "Ne haszn√°lj emojikat"
        
        system_prompt = f"""
        Te egy szak√©rt≈ë k√∂z√∂ss√©gi m√©dia tartalomk√©sz√≠t≈ë vagy. A feladatod hogy platform-specifikus posztokat gener√°lj.
        
        Platform korl√°tok:
        - Facebook: max 63206 karakter, max 30 hashtag
        - Instagram: max 2200 karakter, max 30 hashtag, 2 k√©p √∂tlet kell
        - LinkedIn: max 1300 karakter, max 3 hashtag, professzion√°lis hangnem
        - X (Twitter): max 280 karakter, max 2 hashtag
        
        √Åltal√°nos szab√°lyok:
        - Magyar nyelv haszn√°lata (angol szavak csak indokolt esetben)
        - {emoji_instruction}
        - Hashtag-ek relevancia alapj√°n legyenek rangsorolva
        
        FONTOS: V√°laszolj CSAK valid JSON form√°tumban, semmi m√°ssal! Ne √≠rj semmilyen sz√∂veget a JSON el√© vagy m√∂g√©!
        """
        
        human_prompt = f"""
        Kontextus elemz√©s: {json.dumps(context, ensure_ascii=False)}
        Kamp√°ny√ºzenet: {campaign_message}
        C√©lk√∂z√∂ns√©g: {target_audience}
        Hangnem: {tone}
        
        K√©sz√≠ts egy optimaliz√°lt posztot minden platformra. V√°laszold CSAK JSON form√°tumban:
        {{
            "facebook": {{
                "text": "...",
                "hashtags": ["tag1", "tag2"]
            }},
            "instagram": {{
                "text": "...",
                "hashtags": ["tag1", "tag2"],
                "image_suggestions": ["k√©p1", "k√©p2"]
            }},
            "linkedin": {{
                "text": "...",
                "hashtags": ["tag1"]
            }},
            "x": {{
                "text": "...",
                "hashtags": ["tag1"]
            }}
        }}
        """
        
        print("üì§ SENDING TO AI:")
        print(f"   Context: {json.dumps(context, ensure_ascii=False)}")
        print(f"   Campaign: {campaign_message}")
        print(f"   Audience: {target_audience}")
        print(f"   Tone: {tone}")
        print(f"   Emojis: {use_emojis}")
        
        print("\nüîß FULL SYSTEM PROMPT:")
        print(system_prompt)
        print("\nüìù FULL HUMAN PROMPT:")
        print(human_prompt)
        
        try:
            messages = [SystemMessage(content=system_prompt), HumanMessage(content=human_prompt)]
            print("\n‚è≥ Sending request to Groq API...")
            response = await self.llm.ainvoke(messages)
            
            # Clean the response content to extract JSON
            content = response.content.strip()
            
            print(f"\nüì• RAW AI RESPONSE:")
            print(f"   Length: {len(content)} characters")
            print(f"   Content: {content}")
            
            # Try to find JSON in the response
            json_start = content.find('{')
            json_end = content.rfind('}') + 1
            
            if json_start != -1 and json_end > json_start:
                json_content = content[json_start:json_end]
                print(f"\nüîç EXTRACTED JSON:")
                print(json_content)
                
                parsed_response = json.loads(json_content)
                print(f"\n‚úÖ PARSED JSON RESPONSE:")
                print(json.dumps(parsed_response, indent=2, ensure_ascii=False))
                logger.info("Successfully parsed posts generation response")
                return parsed_response
            else:
                raise json.JSONDecodeError("No JSON found in response", content, 0)
                
        except json.JSONDecodeError as e:
            print(f"\n‚ùå JSON PARSE ERROR: {e}")
            print(f"   Trying to extract from: {content}")
            logger.error(f"Failed to parse posts generation response: {content}")
            # Return fallback posts with the campaign message
            fallback = self._generate_fallback_posts(campaign_message, target_audience, tone, use_emojis)
            print(f"üîÑ Using fallback posts: {json.dumps(fallback, indent=2, ensure_ascii=False)}")
            return fallback
        except Exception as e:
            print(f"\n‚ùå AI SERVICE ERROR: {e}")
            logger.error(f"Posts generation failed: {e}")
            fallback = self._generate_fallback_posts(campaign_message, target_audience, tone, use_emojis)
            print(f"üîÑ Using fallback posts due to error: {json.dumps(fallback, indent=2, ensure_ascii=False)}")
            return fallback
    
    async def refine_posts(self, current_posts: Dict, feedback: str) -> Dict[str, Dict]:
        """Third step: Refine posts based on user feedback."""
        
        print("\nüîß AI SERVICE: POST REFINEMENT")
        print("-" * 50)
        
        system_prompt = """
        Te egy szak√©rt≈ë k√∂z√∂ss√©gi m√©dia tartalomk√©sz√≠t≈ë vagy. A felhaszn√°l√≥ visszajelz√©st adott a megl√©v≈ë posztokra, 
        √©s a feladatod hogy jav√≠tsd ≈ëket a visszajelz√©s alapj√°n.
        
        Platform korl√°tok:
        - Facebook: max 63206 karakter, max 30 hashtag
        - Instagram: max 2200 karakter, max 30 hashtag, 2 k√©p √∂tlet kell
        - LinkedIn: max 1300 karakter, max 3 hashtag, professzion√°lis hangnem
        - X (Twitter): max 280 karakter, max 2 hashtag
        
        FONTOS: V√°laszolj CSAK valid JSON form√°tumban, semmi m√°ssal!
        """
        
        human_prompt = f"""
        Jelenlegi posztok: {json.dumps(current_posts, ensure_ascii=False)}
        
        Felhaszn√°l√≥i visszajelz√©s: {feedback}
        
        Jav√≠tsd a posztokat a visszajelz√©s alapj√°n. V√°laszold CSAK JSON form√°tumban:
        {{
            "facebook": {{
                "text": "...",
                "hashtags": ["tag1", "tag2"]
            }},
            "instagram": {{
                "text": "...",
                "hashtags": ["tag1", "tag2"],
                "image_suggestions": ["k√©p1", "k√©p2"]
            }},
            "linkedin": {{
                "text": "...",
                "hashtags": ["tag1"]
            }},
            "x": {{
                "text": "...",
                "hashtags": ["tag1"]
            }}
        }}
        """
        
        print("üì§ SENDING TO AI:")
        print(f"   Current posts: {json.dumps(current_posts, ensure_ascii=False)}")
        print(f"   Feedback: {feedback}")
        
        print("\nüîß FULL SYSTEM PROMPT:")
        print(system_prompt)
        print("\nüìù FULL HUMAN PROMPT:")
        print(human_prompt)
        
        try:
            messages = [SystemMessage(content=system_prompt), HumanMessage(content=human_prompt)]
            print("\n‚è≥ Sending refinement request to Groq API...")
            response = await self.llm.ainvoke(messages)
            
            content = response.content.strip()
            
            print(f"\nüì• RAW AI RESPONSE:")
            print(f"   Length: {len(content)} characters")
            print(f"   Content: {content}")
            
            # Try to find JSON in the response
            json_start = content.find('{')
            json_end = content.rfind('}') + 1
            
            if json_start != -1 and json_end > json_start:
                json_content = content[json_start:json_end]
                print(f"\nüîç EXTRACTED JSON:")
                print(json_content)
                
                parsed_response = json.loads(json_content)
                print(f"\n‚úÖ PARSED REFINEMENT RESPONSE:")
                print(json.dumps(parsed_response, indent=2, ensure_ascii=False))
                logger.info("Successfully parsed refinement response")
                return parsed_response
            else:
                raise json.JSONDecodeError("No JSON found in refinement response", content, 0)
                
        except json.JSONDecodeError as e:
            print(f"\n‚ùå REFINEMENT JSON PARSE ERROR: {e}")
            print(f"   Trying to extract from: {content}")
            logger.error(f"Failed to parse refinement response: {content}")
            print("üîÑ Returning original posts due to parse error")
            return current_posts
        except Exception as e:
            print(f"\n‚ùå REFINEMENT AI SERVICE ERROR: {e}")
            logger.error(f"Posts refinement failed: {e}")
            print("üîÑ Returning original posts due to error")
            return current_posts
    
    def _generate_fallback_posts(self, campaign_message: str, target_audience: str, 
                                tone: str, use_emojis: bool) -> Dict[str, Dict]:
        """Generate fallback posts when AI service fails."""
        print("\nüîÑ GENERATING FALLBACK POSTS")
        print("-" * 30)
        
        emoji = "üéØ" if use_emojis else ""
        
        tone_prefix = {
            "friendly": f"Szia {target_audience}! {emoji}",
            "professional": f"Tisztelt {target_audience}!",
            "humorous": f"Hah√≥ {target_audience}! üòÑ" if use_emojis else f"Hah√≥ {target_audience}!",
            "casual": f"Hey {target_audience}! {emoji}",
            "formal": f"Tisztelt {target_audience}!"
        }.get(tone, "")
        
        base_text = f"{tone_prefix} {campaign_message}"
        
        fallback = {
            "facebook": {
                "text": f"{base_text}\n\nK√∂vess minket tov√°bbi friss√≠t√©sek√©rt!",
                "hashtags": ["#szakmai", "#fejl≈ëd√©s", "#tr√©ning"]
            },
            "instagram": {
                "text": base_text,
                "hashtags": ["#szakmai", "#fejl≈ëd√©s", "#tr√©ning", "#workshop"],
                "image_suggestions": ["Tr√©ning fot√≥", "R√©sztvev≈ëk k√©pe"]
            },
            "linkedin": {
                "text": f"{base_text}\n\nCsatlakozz szakmai k√∂z√∂ss√©g√ºnkh√∂z!",
                "hashtags": ["#szakmai", "#fejl≈ëd√©s"]
            },
            "x": {
                "text": base_text[:250],  # Truncate for Twitter limit
                "hashtags": ["#szakmai", "#tr√©ning"]
            }
        }
        
        print(f"üìã Generated fallback:")
        print(json.dumps(fallback, indent=2, ensure_ascii=False))
        return fallback